# e2es-orchestrator

## Prerequisites

- A storage root folder must be created ( e.g. `C:\PDGS_NAS_folder` ); this is used as a I/O directory for each processor. Internal folder structure must mimic ICD specifications
- A backup root folder must be created (e.g. `C:\data_backups`);  this is used for storing orchestrator's run backups and PAM related files. This folder must contain a `PAM` fodler (e.g. `C:\data_backups\PAM`)
- Each processor must be installed properly ( following processor's release notes / instructions / readme files )
- Each processor must be configured properly
- It is suggested to teast each processor before use in the orchestration

## Installation

- Install [miniconda](https://docs.conda.io/en/latest/miniconda.html)
- Open anaconda powershell prompt ( find it using the Windows search bar )
- `conda update conda`
- `cd /path/to/e2es-orchestrator`
- `conda env create -f environment.yml`
- `cp configurations.sample.yaml configurations.yaml`

## Configuration

- `start`: identify the workflow starting processor; possible values are listed in 'processors' fields (keys)
- `end`: identify the workflow ending processor; possible values are listed in 'processors' fields (keys); this ending processor cannot sit before the one in 'start' field  (following the order of the list in 'processors' field)
- `logLevel`: only for debugging purposes
- `dataRoot`: absolute path to storage folder ( e.g. `C:\PDGS_NAS_folder` )
- `backupRoot`: absolute path to backup folder (e.g. `C:\data_backups`)
- `backupFile`: (optional) filename (without extension) to a backup file in the `backupRoot` generated during a previous run; if present, the orchestrator will load data from this backup into `dataRoot` specific folders before starting a new run
- `dryMode`: only for debugging purposes; will be removed in future releases
- `workingDirectory`: absolute path to processor delivery folder; internal folder structure must mimic ICD structure 
- `executable` or `script`: relative path to processor executable or python script

### Example
```yaml
start: L1_A 
end: L2_FB
logLevel: DEBUG
dataRoot: 'C:\Users\HydroGNSS\Desktop\PDGS_NAS_folder' 
backupRoot: 'C:\Users\HydroGNSS\Desktop\DataRelease_backups' 
backupFile: 
dryMode: false
processors:
  L1_A: 
    workingDirectory: 'C:\Users\HydroGNSS\Desktop\L1APP\' 
    executable: '.\bin\HSAVERS.exe' 
  L1_B:
    workingDirectory: 'C:\Users\HydroGNSS\Desktop\L1BPP\'
    script: '.\scripts\Run_L1b_Processor_with_dates.py'
  L2_FB: 
    workingDirectory: 'C:\Users\HydroGNSS\Desktop\L2PPFB\'
    executable: '.\bin\L2PP_FB.exe'
  L2_SM:
    workingDirectory: 'C:\Users\HydroGNSS\Desktop\L2PPSSM\'
    executable: '.\bin\SML2PP_start.exe'
    resolution: '25'
    signal: 'L1'
    polarization: 'L'
  L2_FT:
    workingDirectory: 'C:\Users\HydroGNSS\Desktop\L2PPFT\'
    executable: '.\bin\L2PPFT.exe'
  L2_SI:
    workingDirectory: 'C:\Users\HydroGNSS\Desktop\L2PPSI\'
    script: '.\scripts\Run_PSR.py'
```

## Usage 
### Startup
- Open anaconda powershell prompt ( find it using the Windows search bar )
- `cd /path/to/e2es-orchestrator`
- `conda activate e2es-orchestrator`
### Before run
- Check the `configurations.yaml` and apply changes according to your needs
### Run
- `snakemake --cores 1 TARGET`

## Troubleshoot

- If any of the processor failed unexpectedly while executing or the orchestrator is blocked by the user (e.g. Ctrl+c), a `context` folder will be present in the orchestrator folder. Before executing again the orchestrator, that folder must be deleted manually. 
- Backup files must have been generated by the orchestrator. If using manually crafted backup files, the orchstrator could fail.
- Paths which contain spaces usually could cause different problems. It is suggested to work with paths which folder/file names do not contain space characters.


