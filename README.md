# e2es-orchestrator

## Prerequisites

- A storage root folder must be created ( e.g. `C:\PDGS_NAS_folder` ); this is used as a I/O directory for each processor. Internal folder structure must mimic ICD specifications
- A backup root folder must be created (e.g. `C:\data_backups`);  this is used for storing orchestrator's run backups and PAM related files. This folder must contain a `PAM` fodler (e.g. `C:\data_backups\PAM`)
- Each processor must be installed properly ( following processor's release notes / instructions / readme file )
- Each processor must be configured properly
- It is mandatory to test each processor once before use in the orchestration

## Installation

- Install [miniconda](https://docs.conda.io/en/latest/miniconda.html)
- Open anaconda powershell prompt ( find it using the Windows search bar )
- Run command `conda update conda`
- Run command `cd /path/to/e2es-orchestrator`
- Run command `conda env create -f environment.yml`
- Run command `cp configurations.sample.yaml configurations.yaml`

## Usage 
### Automatic
- Open Anaconda Powershell
- Run command `cd /path/to/e2es-orchestrator`
- Run the `run.ps1` script in an Anaconda Powershell
- A GUI opens in order to configure the orchestration process before running 
- A previous configuration is loaded automatically, then each field could be modified according to needs of the operator ( see _Manual > Configuration_ section below as a reference for required inputs )
- Push `Save and RUN` button in the _Orchestrator_ tab to proceed with the simulation 
### Manual
#### Configuration

The configuration file `configurations.yaml` must be set up before each run of the orchestator

Orchestriation process must be configured properly using the following
- `start`: identify the workflow starting processor; possible values are listed in 'processors' fields (keys)
- `end`: identify the workflow ending processor; possible values are listed in 'processors' fields (keys); this ending processor cannot sit before the one in 'start' field  (following the order of the list in 'processors' field)
- `PAM` : set to `True` if it is required to run the PAM process in the end or `False` otherwise
- `logLevel`: only for debugging purposes 
- `dataRoot`: absolute path to storage folder
- `backupRoot`: absolute path to backup folder
- `backupFile`: (optional) filename to a zipped backup file in the `backupRoot` generated by a previous run of the orchestrator; if present, the orchestrator will load data from this backup into `dataRoot` specific folders before starting a new run

Each processor has its own path configuration; under each processor name in the list, following information must be specified
- `workingDirectory`: absolute path to processor delivery folder; internal folder structure must mimic ICD structure 
- `executable` or `script`: relative path ( starting from `workingDirectory` ) to processor executable or a python script

( Check `configurations.sample.yaml` as an example of a working configuration )

#### Run 
- Check the `configurations.yaml` and apply changes according to your need
- Delete `context`, `.snakemake` and `__pycache__` folders if they are present in the `orchestrator` folder
- Open anaconda powershell prompt ( find it using the Windows search bar )
- Run command `cd /path/to/e2es-orchestrator`
- Run command `conda activate e2es-orchestrator`
- Run command `snakemake --cores 1 RUN`




## Troubleshoot
- If any of the processor stops unexpectedly or some other error arise ( e.g. from snakemake ), maybe some transient folders are present in the orchestrator folder. Delete them and try again.
- Backup files must have been generated by the orchestrator. If using manually crafted backup files, the orchstrator could fail.
- Paths which contain spaces usually could cause different problems. It is suggested to work with paths which folder/file names do not contain space characters.


